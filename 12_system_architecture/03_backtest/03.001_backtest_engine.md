
---
# Backtest Core Engine - Technical Reference

**Epoch Trading System v3.0 | XIII Trading LLC

  

---

## What This Document Covers

  This is a focused walkthrough of the **core backtest engine** — the six files that load zones, fetch price data, detect entries, and export results. No secondary processors, no GUI, no indicators. Just the entry detection pipeline from start to finish.

  ---

## The Core Pipeline at a Glance

  
```

Supabase "setups" table          Polygon.io API

        |                               |

        v                               v

  SupabaseZoneLoader              S15Fetcher

  (zone_loader.py +               (s15_fetcher.py)

   supabase_zone_loader.py)             |

        |                               |

        +----------- merge ------------+

                       |

                       v

                 TradeSimulator

              (trade_simulator.py)

                       |

                       v

                  EntryDetector

               (entry_models.py)

                       |

                       v

               List[EntryRecord]

                       |

                       v

                TradesExporter

             (trades_exporter.py)

                       |

                       v

              Supabase "trades_2"

```

  

The CLI runner (`scripts/run_backtest.py`) orchestrates this pipeline.

  

---

  

## File-by-File Breakdown

  

### 1. `config.py` — Module Configuration

  

The single source of settings for the core pipeline.

  

| Setting | Value | Purpose |

|---------|-------|---------|

| `DB_CONFIG` | Host, port, user, pass, SSL | Supabase PostgreSQL connection |

| `POLYGON_API_KEY` | API key string | Polygon.io authentication |

| `API_DELAY` | 0.25 seconds | Rate limit between API calls |

| `API_RETRIES` | 3 | Max retry attempts on failure |

| `ENTRY_START_TIME` | 09:30 ET | Earliest allowed entry |

| `ENTRY_END_TIME` | 15:30 ET | Latest allowed entry |

| `ENTRY_MODELS` | EPCH1=1, EPCH2=2, EPCH3=3, EPCH4=4 | Model ID mapping |

| `VERBOSE` | False | Bar-by-bar logging toggle |

  

---

  

### 2. `data/zone_loader.py` — Zone Data Structure

  

Defines the `ZoneData` dataclass — the standard format every zone loader must produce.

  

```python

@dataclass

class ZoneData:

    ticker: str          # "AAPL"

    ticker_id: str       # "AAPL_021326"

    zone_id: str         # "Z1", "Z2", etc.

    direction: str       # "Bull" or "Bear"

    hvn_poc: float       # High-Volume Node Point of Control price

    zone_high: float     # Upper boundary of the zone

    zone_low: float      # Lower boundary of the zone

    tier: str            # T1, T2, T3 (optional)

    target_id: str       # Target identifier (optional)

    target: float        # Target price (optional)

    rr: float            # Risk/Reward ratio (optional)

    zone_type: str       # "PRIMARY" or "SECONDARY"

```

  

A zone defines a horizontal price range (`zone_low` to `zone_high`) where institutional volume has concentrated. The system watches for price to interact with these zones to generate entry signals.

  

---

  

### 3. `data/supabase_zone_loader.py` — Zone Loading from Database

  

**Class:** `SupabaseZoneLoader`

  

Queries the Supabase `setups` table and returns `ZoneData` objects.

  

**How it works:**

  

1. Connects to Supabase PostgreSQL with SSL

2. Queries `setups` WHERE `date` = trade date AND `setup_type` = PRIMARY or SECONDARY

3. For each row, validates `zone_high` and `zone_low` exist and are numeric

4. If `zone_high < zone_low`, automatically swaps them with a warning

5. If `hvn_poc` is missing, defaults to the midpoint: `(zone_high + zone_low) / 2`

6. Returns a tuple: `(List[ZoneData], List[ZoneData])` — primary zones, secondary zones

  

**Key methods:**

  

| Method | Returns | Purpose |

|--------|---------|---------|

| `load_all_zones()` | `(primary[], secondary[])` | Load both zone types at once |

| `load_primary_zones()` | `List[ZoneData]` | Primary zones only |

| `load_secondary_zones()` | `List[ZoneData]` | Secondary zones only |

| `get_zones_for_ticker(ticker)` | `(primary, secondary)` | Zones for one ticker |

| `get_zone_dict(zone)` | `dict` | Convert to dict format for TradeSimulator |

| `get_available_dates(limit)` | `List[date]` | Dates with setup data |

| `get_setup_count()` | `dict` | Count of PRIMARY/SECONDARY for the date |

  

**The dict format** passed to TradeSimulator:

```python

{

    'zone_high': 187.50,

    'zone_low': 185.00,

    'hvn_poc': 186.25,

    'target': 190.00

}

```

  

---

  

### 4. `data/s15_fetcher.py` — 15-Second Bar Fetcher

  

**Class:** `S15Fetcher`

  

Fetches 15-second OHLCV bars from the Polygon.io REST API.

  

**S15Bar data structure:**

```python

@dataclass

class S15Bar:

    timestamp: datetime      # Eastern Time, timezone-aware

    open: float

    high: float

    low: float

    close: float

    volume: int

    vwap: float              # Volume-weighted average price (optional)

    transactions: int        # Number of transactions (optional)

```

  

**The extended hours window:**

  

S15 bars are fetched for a window spanning two calendar days. This gives the entry detector historical price context before market open:

  

```

Prior Trading Day                    Trade Day

     |                                   |

  16:00 -----> 20:00      04:00 -----> 09:30 -----> 16:00 -----> 20:00

  [after-hours]           [pre-market]  [RTH]        [after-hours]

  

  <-- All included in fetch_bars_extended() -->

```

  

- **Prior day 16:00-20:00:** After-hours from the day before. Builds bar history so the entry detector has price origin context by the time RTH begins.

- **Trade day 04:00-09:30:** Pre-market. More history building.

- **Trade day 09:30-16:00:** Regular trading hours. This is where entries are detected (within the 09:30-15:30 entry window).

- **Trade day 16:00-20:00:** After-hours (included if `include_afterhours=True`).

  

**Prior trading day calculation:** Subtracts 1 day, then skips backward past weekends. Does not account for market holidays (Polygon returns no data for those days, so the fetch simply returns fewer bars).

  

**Key methods:**

  

| Method | Purpose |

|--------|---------|

| `fetch_bars_extended(ticker, date)` | Full extended session (primary method) |

| `fetch_bars(ticker, from, to)` | Raw API call, no filtering |

| `fetch_rth_only(ticker, date)` | 09:30-16:00 only |

| `get_bar_at_time(bars, time)` | Find bar at or just before a time |

  

**API details:**

- Endpoint: `/v2/aggs/ticker/{ticker}/range/15/second/{from}/{to}`

- Limit: 50,000 bars per request (more than sufficient — typical day is ~4,000-5,000)

- Rate limiting: 0.25s between calls (enforced by `_rate_limit()`)

- Timestamps: Polygon returns Unix ms, converted to Eastern timezone `datetime`

  

---

  

### 5. `engine/entry_models.py` — EPCH1-4 Entry Detection

  

**Class:** `EntryDetector`

  

This is the heart of the system. It evaluates every S15 bar against zone boundaries and fires entry signals when specific price action patterns occur.

  

**The four models:**

  

| Model | Zone Type | Pattern | Plain English |

|-------|-----------|---------|---------------|

| EPCH1 | PRIMARY | Continuation | Price starts on one side of the zone, pushes all the way through, closes on the other side |

| EPCH2 | PRIMARY | Rejection | Price approaches the zone from outside, wick dips into it, but closes back outside (bounces off) |

| EPCH3 | SECONDARY | Continuation | Same logic as EPCH1, applied to the secondary zone |

| EPCH4 | SECONDARY | Rejection | Same logic as EPCH2, applied to the secondary zone |

  

**EPCH1 / EPCH3 — Continuation (Traversal) Logic:**

  

The idea: price approaches a zone and blasts through it. The close is on the opposite side from where price originated.

  

```

LONG CONTINUATION:

  

  Scenario A — Opens below, closes above:

    Bar opens BELOW zone_low

    Bar closes ABOVE zone_high

    = Price traversed upward through the entire zone in one bar

  

  Scenario B — Opens inside, closes above (origin was below):

    Bar opens INSIDE the zone (between zone_low and zone_high)

    Bar closes ABOVE zone_high

    AND the most recent close outside the zone was BELOW zone_low

    = Price was working its way up through the zone across multiple bars

  
  

SHORT CONTINUATION:

  

  Scenario A — Opens above, closes below:

    Bar opens ABOVE zone_high

    Bar closes BELOW zone_low

  

  Scenario B — Opens inside, closes below (origin was above):

    Bar opens INSIDE the zone

    Bar closes BELOW zone_low

    AND the most recent close outside the zone was ABOVE zone_high

```

  

**EPCH2 / EPCH4 — Rejection (Wick) Logic:**

  

The idea: price touches the zone and bounces. The wick enters the zone but the close stays on the same side as the open.

  

```

LONG REJECTION:

  

  Scenario A — Opens above, wick enters, closes above:

    Bar opens ABOVE zone_high

    Bar low dips to or below zone_high (wick enters zone)

    Bar closes ABOVE zone_high

    = Price tested the zone from above and rejected upward

  

  Scenario B — Opens inside, closes above (origin was above):

    Bar opens INSIDE the zone

    Bar closes ABOVE zone_high

    AND the most recent close outside the zone was ABOVE zone_high

    = Price briefly dipped into zone but returned above

  
  

SHORT REJECTION:

  

  Scenario A — Opens below, wick enters, closes below:

    Bar opens BELOW zone_low

    Bar high reaches to or above zone_low (wick enters zone)

    Bar closes BELOW zone_low

  

  Scenario B — Opens inside, closes below (origin was below):

    Bar opens INSIDE the zone

    Bar closes BELOW zone_low

    AND the most recent close outside the zone was BELOW zone_low

```

  

**Price Origin Detection:**

  

When a bar opens inside a zone, the detector needs to know which side price came from. It looks backward through `bar_history` (up to 1,000 bars) to find the most recent bar that closed completely outside the zone:

  

```python

def _find_price_origin(self, zone_high, zone_low):

    for bar in reversed(self.bar_history):

        if bar['close'] < zone_low:

            return 'BELOW'

        elif bar['close'] > zone_high:

            return 'ABOVE'

    return None  # No origin found — entry skipped

```

  

If no origin is found (price has been inside the zone for 1,000+ bars, or no history exists), the entry is skipped.

  

**Entry Window Filter:**

  

All signals are gated by the entry window check:

```python

def _is_in_entry_window(self, timestamp):

    bar_time = timestamp.time()

    return ENTRY_START_TIME <= bar_time <= ENTRY_END_TIME

    # 09:30 ET <= bar_time <= 15:30 ET

```

  

Any S15 bar outside this window is ignored, even if it would otherwise trigger a signal. This prevents entries during pre-market, after-hours, and the final 30 minutes of trading.

  

**Bar History Management:**

  

After each bar is processed for signals, it gets appended to `bar_history`. The history is capped at ~1,010 bars and trimmed back to 1,000 when the cap is hit. This provides adequate lookback for price origin detection while keeping memory bounded.

  

```python

def update_prior_bar(self, bar_open, bar_high, bar_low, bar_close):

    self.bar_history.append({...})

    if len(self.bar_history) > MAX_LOOKBACK_BARS + 10:

        self.bar_history = self.bar_history[-MAX_LOOKBACK_BARS:]

```

  

**`EntrySignal` output:**

```python

@dataclass

class EntrySignal:

    model: int           # 1, 2, 3, or 4

    model_name: str      # "EPCH1", "EPCH2", "EPCH3", "EPCH4"

    zone_type: str       # "PRIMARY" or "SECONDARY"

    direction: str       # "LONG" or "SHORT"

    entry_price: float   # The bar's close price

    entry_time: datetime  # The bar's timestamp

    bar_index: int       # Position in the S15 bar sequence

    zone_high: float     # Zone boundary that was tested

    zone_low: float      # Zone boundary that was tested

```

  

**Critical design detail:** The entry price is always the **bar's close price**, not the zone boundary. This is because the S15 bar close is the confirmed price — the moment we know the condition is met.

  

---

  

### 6. `engine/trade_simulator.py` — Entry Collection

  

**Class:** `TradeSimulator`

  

Despite its name, this class does no simulation. It is an orchestrator that feeds S15 bars into the `EntryDetector` and collects the resulting `EntryRecord` objects.

  

**How it works:**

  

1. Initialized with a ticker and trade date

2. Zones are set via `set_zones(primary_dict, secondary_dict)`

3. For each S15 bar, `process_bar_entries_only()` is called:

   - Passes the bar to `EntryDetector.check_all_entries()`

   - For each signal returned, generates a `trade_id` and creates an `EntryRecord`

   - Appends to internal `entries` list

   - **Then** updates the detector's bar history (important: history update happens *after* signal detection, so the current bar is not in the lookback when checking for price origin)

4. After all bars are processed, `get_entries()` returns the complete list

  

**Trade ID Generation:**

  

```python

def generate_trade_id(ticker, entry_time, model_name):

    date_str = entry_time.strftime('%m%d%y')   # MMDDYY

    time_str = entry_time.strftime('%H%M')      # HHMM

    return f"{ticker}_{date_str}_{model_name}_{time_str}"

  

# Examples:

# AAPL_021326_EPCH1_0945

# SPY_021326_EPCH2_1130

# QQQ_021326_EPCH3_1415

```

  

Format: `{TICKER}_{MMDDYY}_{MODEL}_{HHMM}`

  

This creates a human-readable, unique identifier. In the rare case two entries trigger on the same bar for the same model, the exporter appends a counter (`_1`, `_2`, etc.).

  

**`EntryRecord` output:**

```python

@dataclass

class EntryRecord:

    trade_id: str        # "AAPL_021326_EPCH1_0945"

    date: str            # "2026-02-13"

    ticker: str          # "AAPL"

    model: str           # "EPCH1"

    zone_type: str       # "PRIMARY"

    direction: str       # "LONG"

    zone_high: float     # 187.50

    zone_low: float      # 185.00

    entry_price: float   # 187.75

    entry_time: datetime  # 2026-02-13 09:45:00-05:00

```

  

---

  

### 7. `data/trades_exporter.py` — Database Export

  

**Class:** `TradesExporter`

  

Writes `EntryRecord` objects to the Supabase `trades_2` table.

  

**Export flow:**

  

```

1. Connect to Supabase (psycopg2, SSL required)

       |

2. Ensure daily_sessions record exists

   INSERT INTO daily_sessions (date, export_source, export_version)

   VALUES ('2026-02-13', 'backtest_runner', '4.0')

   ON CONFLICT (date) DO NOTHING

       |

3. Clear existing entries for the date (if clear_existing=True)

   DELETE FROM trades_2 WHERE date = '2026-02-13'

       |

4. Build value tuples from EntryRecord list

   - Handles both dataclass objects (hasattr trade_id) and dicts

   - Deduplicates trade_ids with counter suffix

   - Extracts time from datetime/time/string flexibly

       |

5. Batch insert with upsert

   INSERT INTO trades_2 (...) VALUES %s

   ON CONFLICT (trade_id) DO UPDATE SET

       entry_price = EXCLUDED.entry_price,

       entry_time = EXCLUDED.entry_time,

       updated_at = NOW()

       |

6. COMMIT (single transaction for the entire export)

       |

7. Close connection

```

  

**Duplicate trade_id handling:**

  

If two entries produce the same `trade_id` (same ticker, same model, same minute), the exporter appends a counter:

  

```python

seen_trade_ids = {}

for trade in trades:

    base_trade_id = trade.trade_id

    if base_trade_id in seen_trade_ids:

        seen_trade_ids[base_trade_id] += 1

        unique_trade_id = f"{base_trade_id}_{seen_trade_ids[base_trade_id]}"

    else:

        seen_trade_ids[base_trade_id] = 0

        unique_trade_id = base_trade_id

  

# First occurrence:  AAPL_021326_EPCH1_0945

# Second occurrence: AAPL_021326_EPCH1_0945_1

# Third occurrence:  AAPL_021326_EPCH1_0945_2

```

  

**`ExportStats` return value:**

```python

@dataclass

class ExportStats:

    trades_exported: int    # Number successfully inserted

    trades_skipped: int     # Number skipped (unused currently)

    errors: List[str]       # Error messages if any

    success: bool           # True if errors list is empty

```

  

**Convenience function:**

  

```python

export_trades(trades, trade_date, verbose=True)

```

  

Creates a `TradesExporter`, calls `export_trades()`, and returns `ExportStats`. This is what the CLI runner calls.

  

---

  

### 8. `scripts/run_backtest.py` — CLI Orchestrator

  

This is the script that ties everything together. The GUI launches it as a subprocess via QProcess.

  

**Command line interface:**

  

```

python run_backtest.py <date> [options]

  

Arguments:

  date                    Trading date in YYYY-MM-DD format

  

Options:

  --dry-run               Run detection but don't write to database

  --no-export             Skip the Supabase export step

  --m1-bars               After detection, fetch M1 bars (secondary processor)

  --m1-indicators         After detection, calculate M1 indicators (secondary processor)

```

  

**Execution sequence:**

  

```

Step 1: Parse arguments

    |

Step 2: Print banner with mode, date, and enabled options

    |

Step 3: Load zones

    |   SupabaseZoneLoader(trade_date)

    |   -> primary_zones, secondary_zones

    |   -> extract unique tickers, sort alphabetically

    |

Step 4: For each ticker:

    |   a. Find this ticker's primary and secondary zone

    |   b. Convert zones to dict format

    |   c. Fetch S15 bars via S15Fetcher.fetch_bars_extended()

    |   d. Create TradeSimulator(ticker, trade_date)

    |   e. Set zones on simulator

    |   f. Loop through every S15 bar:

    |      simulator.process_bar_entries_only(bar)

    |   g. Collect entries: simulator.get_entries()

    |   h. Print per-ticker summary

    |

Step 5: Print overall summary

    |   Total entries, by model, by direction, by zone type

    |

Step 6: Export to trades_2 (unless --dry-run or --no-export)

    |   export_trades(all_entries, trade_date)

    |

Step 7: Run M1 bars processor (if --m1-bars and not --dry-run)

    |   subprocess.run(m1_bars_runner.py)

    |

Step 8: Run M1 indicators processor (if --m1-indicators and not --dry-run)

    |   subprocess.run(m1_indicator_bars_2/runner.py)

    |

Step 9: Print "ALL COMPLETE"

```

  

**Important detail — the `[X/N]` progress pattern:**

  

The runner prints progress markers like `[1/3]`, `[2/5]`, etc. The GUI's `main_window.py` parses these with a regex to update the progress bar. If you modify the print statements, maintain this pattern or the progress bar breaks.

  

---

  

## The `trades_2` Table

  

The sole output of the core pipeline.

  

```sql

CREATE TABLE trades_2 (

    trade_id    VARCHAR PRIMARY KEY,    -- AAPL_021326_EPCH1_0945

    date        DATE NOT NULL,          -- 2026-02-13

    ticker      VARCHAR NOT NULL,       -- AAPL

    model       VARCHAR NOT NULL,       -- EPCH1 / EPCH2 / EPCH3 / EPCH4

    zone_type   VARCHAR NOT NULL,       -- PRIMARY / SECONDARY

    direction   VARCHAR NOT NULL,       -- LONG / SHORT

    zone_high   NUMERIC,               -- 187.50

    zone_low    NUMERIC,               -- 185.00

    entry_price NUMERIC,               -- 187.75

    entry_time  TIME,                  -- 09:45:00

    created_at  TIMESTAMPTZ DEFAULT NOW(),

    updated_at  TIMESTAMPTZ DEFAULT NOW()

);

  

-- Indexes

CREATE INDEX idx_trades_2_date ON trades_2 (date);

CREATE INDEX idx_trades_2_ticker ON trades_2 (ticker);

CREATE INDEX idx_trades_2_model ON trades_2 (model);

```

  

**Design note:** This table is intentionally minimal — 10 data columns plus 2 timestamps. There are no exit prices, no stop losses, no P&L, no indicators. All of that is computed downstream by secondary processors that read from this table.

  

---

  

## Processing Order Within a Bar

  

Understanding the exact order of operations within `process_bar_entries_only()` matters:

  

```

For each S15 bar:

  

  1. EntryDetector.check_all_entries() runs FIRST

     - Checks EPCH1 on primary zone (continuation)

     - Checks EPCH2 on primary zone (rejection)

     - Checks EPCH1 logic on secondary zone -> EPCH3

     - Checks EPCH2 logic on secondary zone -> EPCH4

     - Price origin lookback uses bar_history (does NOT include current bar)

  

  2. Signals are collected and converted to EntryRecords

  

  3. EntryDetector.update_prior_bar() runs LAST

     - Current bar is added to bar_history

     - History is trimmed if over 1,010 bars

```

  

This means: when the detector checks for price origin, it's looking at all bars **prior to** the current bar. The current bar's data is not yet in the history during detection. This is correct — you want to know where price *was*, not where it *is*.

  

---

  

## Edge Cases and Guardrails

  

**No zones for a date:**

The runner prints "No zones found" and returns an empty entry list. No API calls are made.

  

**No S15 bars for a ticker:**

The runner prints "No S15 data available" and skips to the next ticker. This can happen with illiquid tickers or on holidays.

  

**Zone with zone_high < zone_low:**

The `SupabaseZoneLoader` automatically swaps them and prints a warning. Detection proceeds normally.

  

**Missing zone_high or zone_low:**

The zone is skipped entirely. The ticker may still have its other zone type processed.

  

**Bar opens inside zone with no price origin:**

`_find_price_origin()` returns `None`, and the entry is not triggered. This prevents false signals when the system has insufficient history.

  

**Duplicate trade_ids:**

The exporter appends `_1`, `_2`, etc. The SQL upsert (`ON CONFLICT DO UPDATE`) also handles collisions at the database level, updating `entry_price`, `entry_time`, and `updated_at`.

  

**Weekends and holidays:**

Prior trading day calculation skips Saturdays and Sundays. Holidays are not explicitly handled — Polygon simply returns no data, and the fetcher returns an empty list.

  

**Multiple entries per bar:**

A single S15 bar can theoretically trigger up to 4 entries (EPCH1 long, EPCH1 short, EPCH2 long, EPCH2 short — though long+short on the same model would be contradictory in practice). Each is recorded as a separate `EntryRecord`.

  

---

  

## Example Walkthrough

  

**Scenario:** AAPL on 2026-02-13, Primary zone $185.00 - $187.50, direction Bull.

  

```

09:30:00  Bar: O=184.80  H=185.20  L=184.50  C=184.90

          -> Opens below zone, closes below zone -> No signal

          -> Added to history

  

09:30:15  Bar: O=184.90  H=186.00  L=184.85  C=185.50

          -> Opens below zone, closes INSIDE zone -> No signal

             (EPCH1 needs close ABOVE zone_high to trigger)

          -> Added to history

  

09:30:30  Bar: O=185.50  H=188.00  L=185.40  C=187.75

          -> Opens inside zone, closes above zone_high (187.75 > 187.50)

          -> Price origin check: look back...

             09:30:15 closed at 185.50 (inside zone, skip)

             09:30:00 closed at 184.90 (BELOW zone_low 185.00) -> origin = BELOW

          -> EPCH1 LONG triggered!

          -> EntrySignal: EPCH1, LONG, $187.75, 09:30:30

          -> trade_id: AAPL_021326_EPCH1_0930

          -> Added to history

  

...detection continues for remaining ~1,500 RTH bars...

```

  

---

  

## File Dependency Map

  

```

config.py

    ^

    |--- used by all files below

    |

data/zone_loader.py          (no dependencies beyond stdlib)

    ^

    |

data/supabase_zone_loader.py (imports: config, zone_loader, psycopg2)

  

data/s15_fetcher.py          (imports: config, requests, pytz)

  

engine/entry_models.py       (imports: config)

    ^

    |

engine/trade_simulator.py    (imports: config, entry_models)

  

data/trades_exporter.py      (imports: config, psycopg2)

  

scripts/run_backtest.py      (imports: config, supabase_zone_loader,

                               s15_fetcher, trades_exporter, trade_simulator)

```

  

Every file imports from `config.py`. The CLI runner imports from all data and engine modules. No circular dependencies exist.








---
Parent:[[03_backtest]]